{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico Final - Cargar datos a InfluxDB\n",
    "<br/>\n",
    "\n",
    "## Curso de Especialización en Inteligencia Artificial\n",
    "## Aprendizaje de Máquina II\n",
    "<br/>\n",
    "\n",
    "### Autor: Maximiliano Torti\n",
    "### Fecha: 07/10/21\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este Notebook se implementaran las funciones para cargar datos a la base de datos de influxDB. Los datos se cargan mediante el protocolo flux, que tiene el siguiente formato:\n",
    "\n",
    "{medicion},{tag1}={valor_tag1},{tag2}={valor_tag2} {campo1}={valor_campo1},{campo2}={valor_campo2} {Timestamp}\n",
    "\n",
    "Donde:\n",
    "\n",
    "- Medicion es obligatorio y puede tener cualquier nombre, no tiene mayor trascendencia.\n",
    "- Los tags son opcionales y permiten definir y diferenciar las series de tiempo.\n",
    "- Los campos indican los valores numéricos de las curvas que componen una serie de tiempo.\n",
    "- El timestamp es el tiempo del punto correspondiente.\n",
    "- Tags, campos y timestamp se separan por un espacio.\n",
    "\n",
    "Para mayor entendimiento, se agrega el siguiente ejemplo:\n",
    "\n",
    "- system,signal=PS1,cycle=1 value=3.33 1633867200000\n",
    "\n",
    "La query anterior, agregaría a la medición system, una serie de tiempo definidia por el campo señal igual a PS1 y ciclo igual a 1, y el valor 3.33 a su curva \"value\" en el tiempo 1633867200000 (equivalente a 10/10/2021 12:00:00). \n",
    "Existe una cierta flexibilidad en las definiciones ya que por ejemplo \"cycle\" podría ser un campo en lugar de un tag. Esto depende de si cycle nos interesa como metadato de la serie de tiempo o como \"valor graficable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará el API HTTP de influxDB mediante el modulo request de python insertar los datos a la base. Como nota, python posee un modulo conector desarrollado para influxDB que facilita ciertas tareas, pero en la práctica se observó una muy pobre performance del último con alta cantidad de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27351,
     "status": "ok",
     "timestamp": 1627737680758,
     "user": {
      "displayName": "David Broin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjI6t2tgepcScZHHqnM6kMZPnHyLsfiibDgfKUHQQ=s64",
      "userId": "12597647295470931357"
     },
     "user_tz": 300
    },
    "id": "3y70pCV1XicU",
    "outputId": "5eaba7c5-0836-43a2-cf02-bdf279eec924"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6536,
     "status": "ok",
     "timestamp": 1627738127416,
     "user": {
      "displayName": "David Broin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjI6t2tgepcScZHHqnM6kMZPnHyLsfiibDgfKUHQQ=s64",
      "userId": "12597647295470931357"
     },
     "user_tz": 300
    },
    "id": "6BMwoizJvL9X",
    "outputId": "33c7e080-f819-431d-bc2b-841aa042c652"
   },
   "outputs": [],
   "source": [
    "path = './dataset/'\n",
    "\n",
    "with open(path+ 'df_data_structured.pkl','rb') as file:\n",
    "    df_x=pkl.load(file)\n",
    "\n",
    "with open(path + 'df_output_structured.pkl','rb') as file:\n",
    "    df_y=pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205, 6000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFLUX_URL='127.0.0.1'\n",
    "ORG = \"Maxi\"\n",
    "BUCKET_NAME = \"HydraulicSystem\"\n",
    "QUERY_URI='http://{}:8086/api/v2/write?org={}&bucket={}&precision=ms'.format(INFLUX_URL,ORG,BUCKET_NAME)\n",
    "INFLUX_TOKEN=\"BjUgOzZ3jhI6duhKPIOQiiNmxD7vHqrpsaPuQVSognmHfkTAyoKHtSQPiXQHz6vth2TRE922ZVb7WmeRzRJbrw==\"\n",
    "headers = {}\n",
    "headers['Authorization'] = 'Token {}'.format(INFLUX_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data generation in line protocol and http write total time: 2028.6867659999998s\n"
     ]
    }
   ],
   "source": [
    "# Generamos los datos de input en batch en protocolo flux line y realizamos la escritura con post HTTP.\n",
    "# Calculamos el tiempo que demorado para todos los datos de input\n",
    "\n",
    "http_write_start_time = time.perf_counter()\n",
    "\n",
    "init_timestamp = 1633521600000 # 06/10/2021 12:00. Epoch in ms\n",
    "time_between_cycles = 300000 # 5 min in ms\n",
    "time_per_point = 10 # 100 Hz \n",
    "\n",
    "# Generate influxdb line protocol data in batch\n",
    "for col in df_x.dtype.names:\n",
    "    for cycle in range(df_x[col].shape[0]):\n",
    "        data = []\n",
    "        for point in range(df_x[col].shape[1]):\n",
    "            if not(np.isnan(df_x[col][cycle,point])):\n",
    "                timestamp = init_timestamp + time_between_cycles * cycle + time_per_point * point\n",
    "                data.append(\"system,signal=\"+col+\",cycle=\"+str(cycle+1)+\" value=\"+str(df_x[col][cycle,point])+\" \"+\n",
    "                            str(timestamp))\n",
    "        batch_data = '\\n'.join(data)\n",
    "        response=requests.post(QUERY_URI, data=batch_data, headers=headers)\n",
    "\n",
    "http_write_end_time = time.perf_counter()\n",
    "\n",
    "print(\"Batch data generation in line protocol and http write total time: {time}s\"\n",
    "      .format(time=http_write_end_time - http_write_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escribir los datos de 17 señales que cubren aproximadamente 2205 ciclos de 1 minuto, es decir, aproximadamente 37 horas de operación, le demoró aproximadamente 30 minutos, por lo que el ratio de escritura es relativamente bueno. Bastante bueno en realidad, si quisieramos cargar 1 año de operación, extrapolando, demoraría aproximadamente unos 5 días lo cual es razonable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch output data generation in line protocol and http write total time: 0.2928607999999713s\n"
     ]
    }
   ],
   "source": [
    "# En el caso del otuput, generaremos un punto al final de cada ciclo que resuma la condición deducida de cada elemento,\n",
    "# simulando como si un modelo tomara el ciclo cuando finaliza, procesara y escribiese el resultado en la base de datos\n",
    "\n",
    "http_write_start_time = time.perf_counter()\n",
    "\n",
    "for col in df_y.dtype.names:\n",
    "    data_y = []\n",
    "    for cycle in range(df_y[col].shape[0]):\n",
    "        timestamp = init_timestamp + time_between_cycles * cycle + time_per_point * df_x.shape[1]\n",
    "        data_y.append(\"system,component=\"+col.replace(\" \",\"\")+\",cycle=\"+str(cycle+1)+\" value=\"+str(df_y[col][cycle])+\" \"\n",
    "                      +str(timestamp))\n",
    "    batch_data_y = '\\n'.join(data_y)\n",
    "    requests.post(QUERY_URI, data=batch_data_y, headers=headers)\n",
    "        \n",
    "http_write_end_time = time.perf_counter()\n",
    "\n",
    "print(\"Batch output data generation in line protocol and http write total time: {time}s\"\n",
    "      .format(time=http_write_end_time - http_write_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagenes generadas desde el cliente por defecto de InfluxDB donde se observa la carga de las señales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Señales de entrada**\n",
    "\n",
    "<br />\n",
    "\n",
    "<div style=\"clear: both\">\n",
    "<img src=\"img/InfluxDB_input_data.jpg\" style=\"width: 1000px;float:left\">\n",
    "</div>\n",
    "\n",
    "<div style=\"clear: both\">\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "\n",
    "**Señales de salida**\n",
    "\n",
    "<br />\n",
    "\n",
    "<div style=\"clear: both\">\n",
    "<img src=\"img/InfluxDB_output_data.jpg\" style=\"width: 1000px;float:left\">\n",
    "</div>\n",
    "\n",
    "<div style=\"clear: both\">\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "\n",
    "**Ejemplo de dashboard operativo**\n",
    "\n",
    "<br />\n",
    "\n",
    "<div style=\"clear: both\">\n",
    "<img src=\"img/InfluxDB_dashboard_example.jpg\" style=\"width: 1000px;float:left\">\n",
    "</div>\n",
    "\n",
    "<div style=\"clear: both\">\n",
    "</div>\n",
    "\n",
    "<br />"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de 2Co - CEIA - Ciclo de vida Proyecto ML - Práctica.ipynb",
   "provenance": [
    {
     "file_id": "15rw9iMPol2-M76EYrMDLU9PUdu0os2tt",
     "timestamp": 1627738944725
    },
    {
     "file_id": "1yvsfdRg0F6dzvLs2sCauhHraUCUCq-hP",
     "timestamp": 1625319235465
    },
    {
     "file_id": "1uTJ4IZ7L9PcDnjp9Ref86ObHCx2rU72D",
     "timestamp": 1621093953735
    },
    {
     "file_id": "18bXh_sh-ghxo33BY7HSwDf38ybjaYv-L",
     "timestamp": 1604352928495
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
